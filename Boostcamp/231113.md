# 일일 회고

## 일일 진도 현황

- [x] PyTorch 기본
  - [x] Introduction to PyTorch (3/3)
  - [x] PyTorch Basics (2/3)
  - [x] PyTorch 프로젝트 구조 이해하기
- [ ] PyTorch 구조 학습하기 1
  - [ ] AutoGrad & Optimizer
  - [ ] PyTorch Dataset & DataLoader
- [x] 기본과제 1) Custom Model 제작
- [ ] 기본과제 2) Custom Model 제작

---
개인 공부 
- [ ] 확률론 기초

## 배운 것

### DL Framework
DL Framework 종류는 많지만 현재는 PyTorch, TensorFlow 양대산맥 구조이다.
부스트캠프 학습 특성 상 우리는 PyTorch 사용한다.

### PyTorch basics

numpy + AutoGrad + DL functions

#### Tensor (class)
ndarray -> Tensor

Tensor 선언 방법은 
1. data to tensor (list 선언 후 torch.tensor(list))
2. ndarray to tensor (torch.from_numpy(nd_array)
3. 밑의 방법 (주로쓰임)

numpy - ndarray
```
import numpy as np
n_array = np.arange(10).reshape(2,5)
print(n_array)
print("ndim :", n_array.ndim, "shape :", n_array.shape)
```
pyTorch - Tensor
```
improt torch
t_array = torch.FloatTensor(n_array)
print(t_array)
print("ndim :", t_array.ndim, "shape :", t_array.shape)
```
- 슬라이싱, bzero, bone, shape, dtype 등등 numpy와 공유하는 사용법이 많다
- tensor는 device에 올려야 사용가능 (cpu: cpu, gpu: cuda)
- [x] numpy의 reshape -> Tensor의 view 를 권장 (이유 다시 공부하기)
- squeeze, unsqueeze 로 dim +-
- vector +-, scalar +- 가능
- dot product는 dot, 행렬 곱은 mm
- softmax, onehot 등 필요한 기능은 찾아보면 왠만하면 다 지원해준다~!
- backward함수를 통해 자동미분 가능

- project templete 사용하는 법

## 궁금한 점

해결 완료
[view와 reshape의 동작원리, 다른점, 장단점](https://velog.io/@seokulee/PyTorch%EC%9D%98-view-reshape-%EC%B0%A8%EC%9D%B4%EC%A0%90) 


## 참고자료

[PyTorch의 view, transpose, reshape](https://inmoonlight.github.io/2021/03/03/PyTorch-view-transpose-reshape/)

[discuss about conttitious vs non-contigius tensor](https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107/2)

[PyTorch의 mm vs matmul](https://neos518.tistory.com/178)

## 할 일 및 계획

- 낮에 못들은 수학 저녁에 확률론 강의 1개 이상 듣자!
