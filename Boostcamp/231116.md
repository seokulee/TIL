# 일일 회고

## 일일 진도 현황

- [x] PyTorch 활용하기
  - [x] Multi-GPU 학습
  - [x] Hyperparameter Tuning
  - [ ] PyTorch Trouybleshooting
- [x] PyTorch 완성하기 (5/10)
- [ ] 기본과제 2) Custom Dataset 및 Custom DataLoader
- [ ] 심화과제 Transfer Learning ...

## 배운 것

### GPU

#### Model Parallel

- 다중 GPU에 학습을 분산
- 모델/데이터 나누기 (2가지)

- 모델 병렬화는 고난이도!
- GPU 끼리 pipeline 구조 만들어서 병렬화 성능 향상

- 데이터를 나눠 GPU할당 후 결과의 평균을 취하는 방법
- minibatch 와 비슷한데 한번에 여러 GPU에서 수행

- DataParallel vs DistributedDataParallel
- 단순 데이터 분배 후 평균 (GPU사용 불균형) vs 각 CPU마다 process 생성

### Hyperparameter Tuning

- 학습률 (learning rate), 모델 크기, Optimizer
- 예전엔 많이 영향을 받음
- detail하게 들어갈때

### Troubleshooting

#### OOM
- 추적이 힘듦
- 메모리 이전상황 파악이 힘듦

- 해결 : (ㅋㅋ) batch size를 줄이고 확인해본다.
- GPUUtil로 memory leak 확인하기.
- cache 삭제하기(memort free)

- loop연산 시 tensor variables는 gpu 메모리 사용
- 1d tensor 는 python 기본 객체로 변환하여처리하기

### Pytorch 완성하기 오답

1. 여러 GPU를 사용하여 학습한 모델을 저장한 후, 단일 GPU에서 이 모델을 불러오려고 한다. 이 때, 단일 GPU 환경에서 모델을 불러올 때 생기는 주요 문제점과 그 해결 방법은 무엇인가?

multi GPU model -> using single GPU
: device 문제가 생긴다.
device 지정하기!
단순히 multi GPU model이니 모델 크기가 클거라 생각했다...

2. TensorBoard의 histogram 기능을 사용하면, 모델의 weight와 bias 분포를 시각적으로 확인할 수 있다. 이를 통해 모델의 학습 과정에서 weight와 bias의 분포가 너무 극단적으로 변화하거나 거의 변화하지 않는 상황을 감지할 수 있다. weight와 bias가 극단적으로 변화하거나 거의 변화하지 않는 상황으로 유추할 수 있는 현상을 모두 고르시오.(learning rate에 따른 변화는 무시한다.)

weight bias 분포는 너무 분포도가 커도 작아도 안된다.! grad 에 직접적인 영향을 준다.
overfitting이나 underfitting의 경우도 분포의 극단적 변화나 변화가 없음에 문제라 생각했는데
그게 아니라 오로지 학습량에 대한 문제였다.(?)

3. PyTorch를 사용하여 모델을 학습시키는 도중, 성능의 변화를 주기적으로 체크하고자 한다. 아래의 설명 중 효과적인 모델 학습 관리 방법과 관련된 것만 고르시오.

A. 모델의 가중치를 정기적으로 저장하고, 가장 좋은 성능을 보인 시점의 가중치를 복원하여 사용한다.
B. 학습률을 고정된 값으로 설정하고, 학습 중 변동하지 않도록 한다.
C. TensorBoard와 같은 도구를 사용하여 학습 중인 모델의 성능, 손실 등의 지표를 시각화한다.
D. 여러 GPU를 사용하여 데이터 병렬 처리를 구현하고, 학습 속도를 향상시킨다.
E. 모든 에포크마다 가중치의 변화를 출력하고, 이를 통해 모델이 수렴하는지 확인한다.

문제는 성능 모니터링에 관한 문제였다.
A와 C는 확실하다 생각하고, D와 E사이에서 고민했는데, 여러 GPU로 데이터 병렬처리, 학습속도 향상이 맞다고 생각했고, 모든 에포크마다 가중치 변화를 출력하면 성능에는 무리가 될 것이라 생각했다.(n번에 1번 등으로 생각함)

근데 D는 학습 성능 속도 향상에 대한 이야기이고, 전체적인 성능에 대한 이야기는 매 에포크마다 확인하고 수정하는 방법이 더 맞는 말 같다.



## 궁금한 점

- [ ] conv 정리하기

[conv](https://supermemi.tistory.com/entry/Convolution%ED%95%A9%EC%84%B1%EA%B3%B1%EC%9D%98-%EC%9B%90%EB%A6%AC%EC%99%80-%EB%AA%A9%EC%A0%81)

## 참고자료


## 할 일 및 계획

-
