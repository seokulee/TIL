# 일일 회고

## 일일 진도 현황

- [x] [Git 특강] init, commit, add, checkout, branch, merge, push, conflict
- [x] [DL Basic] 5 ~ 7강 복습 (LSTM 실습까지)
- [x] [RecSys 이론] 3강 Collaborative Filtering 1
  - [x] 3강 실습
  - [x] 3강 퀴즈 (3/3)
- [ ] [RecSys 이론] 4강 Collaborative Filtering 2
  - [ ] 4강 퀴즈
  - [ ] 기본과제 1

## 배운 것

### Collaborative Filtering(CF)

많은 유저들로부터 얻은 기호 정보를 이용해 유저의 관심사를 자동으로 예측

($\sim$학습 데이터가 많아질수록 성능이 좋아진다)

#### Goal

유저 u가 아이템 i에 부여할 평점을 예측하는 것

#### Step

- 유저-아이템 행렬 생성
- 유사도 기준 정하기
- 행렬 비어있는 값 예측

#### 특징

- 구현이 간단
- 이해가 쉬움
- 데이터가 많아질 경우 확장성이 떨어진다.
- 데이터가 적을 경우 성능이 저하된다.

### Neighborhood-based CF(Memory-based CF)

#### 유저 기반 협업 필터링 UBCF

두 유저간의 유사도를 구한 뒤, 타겟 유저와 유사도가 높은 유저들이 선호하는 아이템을 추천

#### 아이템 기반 협업 필터링 IBCF

두 아이템이 유저들로부터 얼마나 유사한 평점을 받았는가?

### K-Nearest Neighbors CF (KNN CF)

유저와 가장 유사한 K명 유저를 이용해 평점을 예측

K는 hyper parameter

### 유사도 측정법

두 개체간의 유사성을 수량화하는 실수 값 함수 혹은 척도

일반적으로 거리의 역수 개념

#### Mean Squared Difference Similarity

유클리드 거리에 반비례

#### Cosine Similarity

두 벡터의 각도를 이용하여 구할 수 있는 유사도
(내적 ?) 근데 방향만

#### Pearson Similarity

각 벡터를 표본평균으로 정규화한 뒤에 코사인 유사도를 구한 값

#### Jaccard Similarity

집합의 개념을 사용한 유사도

### Rating Prediction

- Average
- Weighted Average : 유사도에 기반한 가중치를 두어서 평균에 반영
- Absolute Rating Formula

1. Average
>$\hat r(u,i) = {\sum_{\omega\in\Omega_i}r(u^{'},i) \over \left\vert\Omega_i\right\vert}$

2.Weight Average
>$\hat r(u,i) = {\sum_{\omega \in \Omega_i} \sin(u,u^{'})r(u^{'},i) \over \sum_{\omega \in \Omega} sin(u,u^{'})}$

#### Absoulute Rating의 한계

유저마다 `기준`이 다름!!

### Relative Rating

유저의 평균 평점에서 `편차`를 사용

-> rating이 아닌 deviation을 예측한다.

Relative Rating
>$\hat r(u,i) = \overline {r_u} + {\sum_{\omega \in \Omega_i} \sin(u,u^{'})\{r(u^{'},i)-\overline{r_{u^{'}}}\} \over \sum_{\omega \in \Omega} sin(u,u^{'})}$

-> Top-N recommendation
위 과정을 통해 얻은 평점이 높은 N개를 추천에 활용하는 것

### Model based collaborative filtering(MBCF)

- parametric ML 사용
- 주어진 데이터를 사용하여 모델을 학습
- 데이터 정보가 파라미터 형태로 모델에 압축

즉, 데이터에 숨겨진 유저-아이템 관계의 잠재적 특성/패턴을 찾음

현업에서 Matrix Factorization 기법이 가장 많이 사용됨

이웃기반에 비해
1. 모델 학습/서빙
2. Sparsity & Scalability Issue 해결
3. Overfitting 방지
4. Limited Coverage 극복

### Implicit Feedback (Another Issue)

Explicit feedback : user의 선호도를 직접적으로 알 수 있는 데이터

Implicit feedback : user의 선호도를 간접적으로 알 수 있는 데이터 (ex. 클릭, 시청여부)

현실에서는 implicit feedback이 훨씬 더 많음

-> 선호도 (1 or 0)

### Latenet Factor Model
(Embedding)

유저와 아이템 관계를 잠재적 요인으로 표현할 수 있다고 보는 모델

유저-아이템 행렬을 저차원의 행렬로 분해하는 방식으로 작동

같은 벡터 공간에서 유저와 아이템 벡터가 놓일 경우 유저와 아이템의 유사한 정도를 확인할 수 있음

### SVD
Singular Value Decomposition

2차원 행렬을 분해하는 방법
- 유저 잠재 요인 행렬
- 잠재 요인 대각행렬
- 아이템 잠재 요인 행렬

선대 차원 축소 기법 중 하나로 분류됨

> Full SVD: $R = U \sum V^T$

> Truncated SVD: $R \approx \hat U \sum_{K} \hat {V^T} = \hat R$

#### 한계점

- 분해하려는 행렬의 Knowledger가 불완전할 때 정의되지 않음
- 결측된 entry를 모두 채우는 Imputation을 통해 Dense Matrix를 만들어 SVD를 수행함
- 정확하지 않은 Imputation은 데이터를 왜곡시키고 예측 성능을 떨어트림

-> 원리차용, 다른 접근방법

### Matrix Factorization(MF)

User-Item 행렬을 저차원의 User와 Item의 latent factor 행렬의 곱으로 분해

관측된 선호도만 모델링에 활용

> $R \approx P \times Q^T = \hat R$<br>
$P \rightarrow \left\vert U \right\vert \times k$<br>
$Q \rightarrow \vert I \vert \times k$

Objective Function

$\underset{P,Q}{min} \sum\limits_{observed r_u,i}(r_{u,i}-p_u^Tqi)^2 + \lambda(\Vert p_u\Vert^2_2 + \Vert q_i \Vert^2_2)$

~ 22:52



## 궁금한 점

## 참고자료

## 할 일 및 계획

기본과제 1 까지 완료하기.

29일 계획
- Transformer 복습
- 4,5,6 강 학습
